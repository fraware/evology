{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "mode = 'static'\n",
    "\n",
    "if mode == 'learning':\n",
    "\n",
    "    standard_coord = pd.read_csv(\"/Users/aymericvie/Documents/GitHub/evology/evology/research/TransferStatus/GainMatrixSingle/data/neutral_combined/static_standard.csv\")\n",
    "    NT_bump_coord = pd.read_csv(\"/Users/aymericvie/Documents/GitHub/evology/evology/research/TransferStatus/GainMatrixSingle/data/neutral_combined/static_NT_bump.csv\")\n",
    "    VI_bump_coord = pd.read_csv(\"/Users/aymericvie/Documents/GitHub/evology/evology/research/TransferStatus/GainMatrixSingle/data/neutral_combined/static_VI_bump.csv\")\n",
    "    TF_bump_coord = pd.read_csv(\"/Users/aymericvie/Documents/GitHub/evology/evology/research/TransferStatus/GainMatrixSingle/data/neutral_combined/static_TF_bump.csv\")\n",
    "\n",
    "if mode == 'static':\n",
    "    standard_coord = pd.read_csv(\"/Users/aymericvie/Documents/GitHub/evology/evology/research/TransferStatus/GainMatrixSingle/data/neutral_static/static_standard.csv\")\n",
    "    NT_bump_coord = pd.read_csv(\"/Users/aymericvie/Documents/GitHub/evology/evology/research/TransferStatus/GainMatrixSingle/data/neutral_static/static_NT_bump.csv\")\n",
    "    VI_bump_coord = pd.read_csv(\"/Users/aymericvie/Documents/GitHub/evology/evology/research/TransferStatus/GainMatrixSingle/data/neutral_static/static_VI_bump.csv\")\n",
    "    TF_bump_coord = pd.read_csv(\"/Users/aymericvie/Documents/GitHub/evology/evology/research/TransferStatus/GainMatrixSingle/data/neutral_static/static_TF_bump.csv\")\n",
    "\n",
    "h = 2/256\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n"
     ]
    }
   ],
   "source": [
    "''' Gain matrix estimation without outliers '''\n",
    "np.set_printoptions(suppress=True)\n",
    "margin = 3\n",
    "\n",
    "# standard_coord = pd.read_csv(\"/Users/aymericvie/Documents/GitHub/evology/evology/research/TransferStatus/GainMatrixSingle/data/static_standard.csv\")\n",
    "\n",
    "clean_standard_coord = pd.DataFrame()\n",
    "\n",
    "new_standard_coord = pd.DataFrame()\n",
    "new_standard_coord = standard_coord[np.abs(standard_coord['NT_DayReturns']-standard_coord['NT_DayReturns'].mean()) <= (margin*standard_coord['NT_DayReturns'].std())]\n",
    "standard_coord_NT_Return = new_standard_coord['NT_DayReturns'].mean()\n",
    "clean_standard_coord['NT_DayReturns'] = 100 * new_standard_coord['NT_DayReturns']\n",
    "\n",
    "new_standard_coord = pd.DataFrame()\n",
    "new_standard_coord = standard_coord[np.abs(standard_coord['VI_DayReturns']-standard_coord['VI_DayReturns'].mean()) <= (margin*standard_coord['VI_DayReturns'].std())]\n",
    "standard_coord_VI_Return = new_standard_coord['VI_DayReturns'].mean()\n",
    "clean_standard_coord['VI_DayReturns'] = 100 * new_standard_coord['VI_DayReturns']\n",
    "\n",
    "new_standard_coord = pd.DataFrame()\n",
    "new_standard_coord = standard_coord[np.abs(standard_coord['TF_DayReturns']-standard_coord['TF_DayReturns'].mean()) <= (margin*standard_coord['TF_DayReturns'].std())]\n",
    "standard_coord_TF_Return = new_standard_coord['TF_DayReturns'].mean()\n",
    "clean_standard_coord['TF_DayReturns'] = 100 * new_standard_coord['TF_DayReturns']\n",
    "\n",
    "print(standard_coord_NT_Return, standard_coord_VI_Return, standard_coord_TF_Return)\n",
    "\n",
    "clean_NT_bump_coord = pd.DataFrame()\n",
    "\n",
    "new_NT_bump_coord = pd.DataFrame()\n",
    "new_NT_bump_coord = NT_bump_coord[np.abs(NT_bump_coord['NT_DayReturns']-NT_bump_coord['NT_DayReturns'].mean()) <= (margin*NT_bump_coord['NT_DayReturns'].std())]\n",
    "NT_bump_NT_Return = new_NT_bump_coord['NT_DayReturns'].mean()\n",
    "clean_NT_bump_coord['NT_DayReturns'] = 100 * new_NT_bump_coord['NT_DayReturns']\n",
    "\n",
    "new_NT_bump_coord = pd.DataFrame()\n",
    "new_NT_bump_coord = NT_bump_coord[np.abs(NT_bump_coord['VI_DayReturns']-NT_bump_coord['VI_DayReturns'].mean()) <= (margin*NT_bump_coord['VI_DayReturns'].std())]\n",
    "NT_bump_VI_Return = new_NT_bump_coord['VI_DayReturns'].mean()\n",
    "clean_NT_bump_coord['VI_DayReturns'] = 100 * new_NT_bump_coord['VI_DayReturns']\n",
    "\n",
    "new_NT_bump_coord = pd.DataFrame()\n",
    "new_NT_bump_coord = NT_bump_coord[np.abs(NT_bump_coord['TF_DayReturns']-NT_bump_coord['TF_DayReturns'].mean()) <= (margin*NT_bump_coord['TF_DayReturns'].std())]\n",
    "NT_bump_TF_Return = new_NT_bump_coord['TF_DayReturns'].mean()\n",
    "clean_NT_bump_coord['TF_DayReturns'] = 100 * new_NT_bump_coord['TF_DayReturns']\n",
    "\n",
    "print(NT_bump_NT_Return, NT_bump_VI_Return, NT_bump_TF_Return)\n",
    "\n",
    "\n",
    "clean_VI_bump_coord = pd.DataFrame()\n",
    "\n",
    "new_VI_bump_coord = pd.DataFrame()\n",
    "new_VI_bump_coord = VI_bump_coord[np.abs(VI_bump_coord['NT_DayReturns']-VI_bump_coord['NT_DayReturns'].mean()) <= (margin*VI_bump_coord['NT_DayReturns'].std())]\n",
    "VI_bump_NT_Return = new_VI_bump_coord['NT_DayReturns'].mean()\n",
    "clean_VI_bump_coord['NT_DayReturns'] = 100 * new_VI_bump_coord['NT_DayReturns']\n",
    "\n",
    "new_VI_bump_coord = pd.DataFrame()\n",
    "new_VI_bump_coord = VI_bump_coord[np.abs(VI_bump_coord['VI_DayReturns']-VI_bump_coord['VI_DayReturns'].mean()) <= (margin*VI_bump_coord['VI_DayReturns'].std())]\n",
    "VI_bump_VI_Return = new_VI_bump_coord['VI_DayReturns'].mean()\n",
    "clean_VI_bump_coord['VI_DayReturns'] = 100 * new_VI_bump_coord['VI_DayReturns']\n",
    "\n",
    "new_VI_bump_coord = pd.DataFrame()\n",
    "new_VI_bump_coord = VI_bump_coord[np.abs(VI_bump_coord['TF_DayReturns']-VI_bump_coord['TF_DayReturns'].mean()) <= (margin*VI_bump_coord['TF_DayReturns'].std())]\n",
    "VI_bump_TF_Return = new_VI_bump_coord['TF_DayReturns'].mean()\n",
    "clean_VI_bump_coord['TF_DayReturns'] = 100 * new_VI_bump_coord['TF_DayReturns']\n",
    "\n",
    "print(VI_bump_NT_Return, VI_bump_VI_Return, VI_bump_TF_Return)\n",
    "\n",
    "\n",
    "clean_TF_bump_coord = pd.DataFrame()\n",
    "new_TF_bump_coord = pd.DataFrame()\n",
    "new_TF_bump_coord = TF_bump_coord[np.abs(TF_bump_coord['NT_DayReturns']-TF_bump_coord['NT_DayReturns'].mean()) <= (margin*TF_bump_coord['NT_DayReturns'].std())]\n",
    "TF_bump_NT_Return = new_TF_bump_coord['NT_DayReturns'].mean()\n",
    "clean_TF_bump_coord['NT_DayReturns'] = 100 * new_TF_bump_coord['NT_DayReturns']\n",
    "\n",
    "\n",
    "new_TF_bump_coord = pd.DataFrame()\n",
    "new_TF_bump_coord = TF_bump_coord[np.abs(TF_bump_coord['VI_DayReturns']-TF_bump_coord['VI_DayReturns'].mean()) <= (margin*TF_bump_coord['VI_DayReturns'].std())]\n",
    "TF_bump_VI_Return = new_TF_bump_coord['VI_DayReturns'].mean()\n",
    "clean_TF_bump_coord['VI_DayReturns'] = 100 * new_TF_bump_coord['VI_DayReturns']\n",
    "\n",
    "new_TF_bump_coord = pd.DataFrame()\n",
    "new_TF_bump_coord = TF_bump_coord[np.abs(TF_bump_coord['TF_DayReturns']-np.nanmean(TF_bump_coord['TF_DayReturns'])) <= (margin*TF_bump_coord['TF_DayReturns'].std())]\n",
    "TF_bump_TF_Return = np.nanmean(new_TF_bump_coord['TF_DayReturns'])\n",
    "clean_TF_bump_coord['TF_DayReturns'] = 100 * new_TF_bump_coord['TF_DayReturns']\n",
    "\n",
    "print(TF_bump_NT_Return, TF_bump_VI_Return, TF_bump_TF_Return)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--NT ROW--\n",
      "         T   dof alternative  p-val       CI95%  cohen-d BF10  power\n",
      "T-test NaN  9789   two-sided    NaN  [nan, nan]      NaN  nan    NaN\n",
      "0.0\n",
      "         T   dof alternative  p-val       CI95%  cohen-d BF10  power\n",
      "T-test NaN  9789   two-sided    NaN  [nan, nan]      NaN  nan    NaN\n",
      "0.0\n",
      "         T   dof alternative  p-val       CI95%  cohen-d BF10  power\n",
      "T-test NaN  9789   two-sided    NaN  [nan, nan]      NaN  nan    NaN\n",
      "0.0\n",
      "--VI ROW--\n",
      "         T   dof alternative  p-val       CI95%  cohen-d BF10  power\n",
      "T-test NaN  9789   two-sided    NaN  [nan, nan]      NaN  nan    NaN\n",
      "0.0\n",
      "         T   dof alternative  p-val       CI95%  cohen-d BF10  power\n",
      "T-test NaN  9789   two-sided    NaN  [nan, nan]      NaN  nan    NaN\n",
      "0.0\n",
      "         T   dof alternative  p-val       CI95%  cohen-d BF10  power\n",
      "T-test NaN  9789   two-sided    NaN  [nan, nan]      NaN  nan    NaN\n",
      "0.0\n",
      "--TF ROW--\n",
      "         T   dof alternative  p-val       CI95%  cohen-d BF10  power\n",
      "T-test NaN  9789   two-sided    NaN  [nan, nan]      NaN  nan    NaN\n",
      "0.0\n",
      "         T   dof alternative  p-val       CI95%  cohen-d BF10  power\n",
      "T-test NaN  9789   two-sided    NaN  [nan, nan]      NaN  nan    NaN\n",
      "0.0\n",
      "         T   dof alternative  p-val       CI95%  cohen-d BF10  power\n",
      "T-test NaN  9789   two-sided    NaN  [nan, nan]      NaN  nan    NaN\n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pingouin/effsize.py:691: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  d = (x.mean() - y) / x.std(ddof=1)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pingouin/effsize.py:691: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  d = (x.mean() - y) / x.std(ddof=1)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pingouin/effsize.py:691: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  d = (x.mean() - y) / x.std(ddof=1)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pingouin/effsize.py:691: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  d = (x.mean() - y) / x.std(ddof=1)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pingouin/effsize.py:691: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  d = (x.mean() - y) / x.std(ddof=1)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pingouin/effsize.py:691: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  d = (x.mean() - y) / x.std(ddof=1)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pingouin/effsize.py:691: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  d = (x.mean() - y) / x.std(ddof=1)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pingouin/effsize.py:691: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  d = (x.mean() - y) / x.std(ddof=1)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pingouin/effsize.py:691: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  d = (x.mean() - y) / x.std(ddof=1)\n"
     ]
    }
   ],
   "source": [
    "import statsmodels as stats \n",
    "import scipy \n",
    "import pingouin as pg\n",
    "\n",
    "def write_signif(res):\n",
    "    if res['p-val'][0] < 0.01:\n",
    "        # signif = str.maketrans('***')\n",
    "        signif = '^{***}'\n",
    "    elif res['p-val'][0] < 0.05:\n",
    "        # signif = str.maketrans('**')\n",
    "        signif = '^{**}'\n",
    "    elif res['p-val'][0] < 0.1:\n",
    "        # signif = str.maketrans('*')\n",
    "        signif = '^{*}'\n",
    "    else:\n",
    "        signif = ''\n",
    "    return signif\n",
    "\n",
    "''' \n",
    "Null hypothesis: means are equal \n",
    "Alternative hypothesis\" means are different \n",
    "\n",
    "For p-value >= alpha: fail to reject null hypothesis\n",
    "For p-value < alpha: reject H0 and accept HA\n",
    "'''\n",
    "\n",
    "print('--NT ROW--')\n",
    "\n",
    "res = pg.ttest(1/h * (clean_NT_bump_coord['NT_DayReturns'] - clean_standard_coord['NT_DayReturns']), 0, correction=False, confidence=0.95)\n",
    "print(res)\n",
    "signif00 = write_signif(res)\n",
    "ci00 = res['CI95%'][0]\n",
    "print(1/h * (clean_NT_bump_coord['NT_DayReturns'] - clean_standard_coord['NT_DayReturns']).mean())\n",
    "\n",
    "\n",
    "res = pg.ttest(1/h  * (clean_VI_bump_coord['NT_DayReturns'] - clean_standard_coord['NT_DayReturns']), 0, correction=False, confidence=0.95)\n",
    "print(res)\n",
    "signif01 = write_signif(res)\n",
    "ci01 = res['CI95%'][0]\n",
    "print(1/h * (clean_VI_bump_coord['NT_DayReturns'] - clean_standard_coord['NT_DayReturns']).mean())\n",
    "\n",
    "res = pg.ttest(1/h * (clean_TF_bump_coord['NT_DayReturns'] - clean_standard_coord['NT_DayReturns']), 0, correction=False, confidence=0.95)\n",
    "print(res)\n",
    "signif02 = write_signif(res)\n",
    "ci02 = res['CI95%'][0]\n",
    "print(1/h * (clean_TF_bump_coord['NT_DayReturns'] - clean_standard_coord['NT_DayReturns']).mean())\n",
    "\n",
    "print('--VI ROW--')\n",
    "\n",
    "res = pg.ttest(1/h * (clean_NT_bump_coord['VI_DayReturns'] - clean_standard_coord['VI_DayReturns']), 0, correction=False, confidence=0.95)\n",
    "print(res)\n",
    "signif10 = write_signif(res)\n",
    "ci10 = res['CI95%'][0]\n",
    "print(1/h * (clean_NT_bump_coord['VI_DayReturns'] - clean_standard_coord['VI_DayReturns']).mean())\n",
    "\n",
    "\n",
    "res = pg.ttest(1/h  * (clean_VI_bump_coord['VI_DayReturns'] - clean_standard_coord['VI_DayReturns']), 0, correction=False, confidence=0.95)\n",
    "print(res)\n",
    "signif11 = write_signif(res)\n",
    "ci11 = res['CI95%'][0]\n",
    "print(1/h * (clean_VI_bump_coord['VI_DayReturns'] - clean_standard_coord['VI_DayReturns']).mean())\n",
    "\n",
    "res = pg.ttest(1/h * (clean_TF_bump_coord['VI_DayReturns'] - clean_standard_coord['VI_DayReturns']), 0, correction=False, confidence=0.95)\n",
    "print(res)\n",
    "signif12 = write_signif(res)\n",
    "ci12 = res['CI95%'][0]\n",
    "print(1/h * (clean_TF_bump_coord['VI_DayReturns'] - clean_standard_coord['VI_DayReturns']).mean())\n",
    "\n",
    "print('--TF ROW--')\n",
    "\n",
    "res = pg.ttest(1/h * (clean_NT_bump_coord['TF_DayReturns'] - clean_standard_coord['TF_DayReturns']), 0, correction=False, confidence=0.95)\n",
    "print(res)\n",
    "signif20 = write_signif(res)\n",
    "ci20 = res['CI95%'][0]\n",
    "print(1/h * (clean_NT_bump_coord['TF_DayReturns'] - clean_standard_coord['TF_DayReturns']).mean())\n",
    "\n",
    "\n",
    "res = pg.ttest(1/h  * (clean_VI_bump_coord['TF_DayReturns'] - clean_standard_coord['TF_DayReturns']), 0, correction=False, confidence=0.95)\n",
    "print(res)\n",
    "signif21 = write_signif(res)\n",
    "ci21 = res['CI95%'][0]\n",
    "print(1/h * (clean_VI_bump_coord['TF_DayReturns'] - clean_standard_coord['TF_DayReturns']).mean())\n",
    "\n",
    "res = pg.ttest(1/h * (clean_TF_bump_coord['TF_DayReturns'] - clean_standard_coord['TF_DayReturns']), 0, correction=False, confidence=0.95)\n",
    "print(res)\n",
    "signif22 = write_signif(res)\n",
    "ci22 = res['CI95%'][0]\n",
    "print(1/h * (clean_TF_bump_coord['TF_DayReturns'] - clean_standard_coord['TF_DayReturns']).mean())\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "GainMatrix = np.zeros((3,3))\n",
    "h = 2/256\n",
    "\n",
    "''' It is mutliplied by 1/h by finite difference, and by 100 to obtain percentages '''\n",
    "\n",
    "GainMatrix[0,0] = round(100/h * (NT_bump_NT_Return - standard_coord_NT_Return),3)\n",
    "GainMatrix[0,1] = round(100/h * (VI_bump_NT_Return - standard_coord_NT_Return),3)\n",
    "GainMatrix[0,2] = round(100/h * (TF_bump_NT_Return - standard_coord_NT_Return),3)\n",
    "\n",
    "GainMatrix[1,0] = round(100/h * (NT_bump_VI_Return - standard_coord_VI_Return),3)\n",
    "GainMatrix[1,1] = round(100/h * (VI_bump_VI_Return - standard_coord_VI_Return),3)\n",
    "GainMatrix[1,2] = round(100/h * (TF_bump_VI_Return - standard_coord_VI_Return),3)\n",
    "\n",
    "GainMatrix[2,0] = round(100/h * (NT_bump_TF_Return - standard_coord_TF_Return),3)\n",
    "GainMatrix[2,1] = round(100/h * (VI_bump_TF_Return - standard_coord_TF_Return),3)\n",
    "GainMatrix[2,2] = round(100/h * (TF_bump_TF_Return - standard_coord_TF_Return),3)\n",
    "\n",
    "# print(GainMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Texttable Table:\n",
      "+----+--------------+--------------+-------------+\n",
      "|    |      NT      |      VI      |     TF      |\n",
      "+====+==============+==============+=============+\n",
      "| NT | 4.184^{***}  | 11.029^{***} | -0.823      |\n",
      "| VI | -2.0^{***}   | -0.369       | 1.053^{*}   |\n",
      "| TF | -3.006^{***} | -2.751^{***} | -2.65^{***} |\n",
      "+----+--------------+--------------+-------------+\n",
      "\\begin{table}\n",
      "\t\\begin{center}\n",
      "\t\t\\begin{tabular}{|C|C|C|C|}\n",
      "\t\t\t\\hline\n",
      "\t\t\t & NT & VI & TF \\\\\n",
      "\t\t\t\\hline\n",
      "\t\t\tNT & 4.184^{***} & 11.029^{***} & -0.823 \\\\\n",
      "\t\t\tVI & -2.0^{***} & -0.369 & 1.053^{*} \\\\\n",
      "\t\t\tTF & -3.006^{***} & -2.751^{***} & -2.65^{***} \\\\\n",
      "\t\t\t\\hline\n",
      "\t\t\\end{tabular}\n",
      "\t\\end{center}\n",
      "\t\\caption{Gain matrix at the equal wealth coordinates. Significance is showed for p-value inferior to 0.01 (***), 0.05 (**) and 0.1 (*).}\n",
      "\\end{table}\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "from texttable import Texttable\n",
    "import latextable\n",
    "\n",
    "rows = [['', 'NT', 'VI', 'TF'],\n",
    "        ['NT', str(GainMatrix[0,0]) + str(signif00), str(GainMatrix[0,1]) + str(signif01), str(GainMatrix[0,2]) + str(signif02)],\n",
    "        ['VI', str(GainMatrix[1,0]) + str(signif10), str(GainMatrix[1,1]) + str(signif11), str(GainMatrix[1,2]) + str(signif12)],\n",
    "        ['TF', str(GainMatrix[2,0]) + str(signif20), str(GainMatrix[2,1]) + str(signif21), str(GainMatrix[2,2]) + str(signif22)]]\n",
    "\n",
    "table = Texttable()\n",
    "table.set_cols_align([\"C\"] * 4)\n",
    "table.set_deco(Texttable.HEADER | Texttable.VLINES | Texttable.BORDER)\n",
    "table.add_rows(rows)\n",
    "\n",
    "\n",
    "print('\\nTexttable Table:')\n",
    "print(table.draw())\n",
    "print(latextable.draw_latex(table, \n",
    "        caption=\"Gain matrix at the equal wealth coordinates. Significance is showed for p-value inferior to 0.01 (***), 0.05 (**) and 0.1 (*).\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Texttable Table:\n",
      "+----+---------------+---------------+---------------+\n",
      "|    |      NT       |      VI       |      TF       |\n",
      "+====+===============+===============+===============+\n",
      "| NT | [3.06 5.45]   | [ 9.96 12.36] | [-2.    0.37] |\n",
      "| VI | [-3.03 -1.27] | [-0.96  0.9 ] | [-0.07  1.68] |\n",
      "| TF | [-4.13 -1.96] | [-3.68 -1.57] | [-4.48 -2.28] |\n",
      "+----+---------------+---------------+---------------+\n",
      "\\begin{table}\n",
      "\t\\begin{center}\n",
      "\t\t\\begin{tabular}{|C|C|C|C|}\n",
      "\t\t\t\\hline\n",
      "\t\t\t & NT & VI & TF \\\\\n",
      "\t\t\t\\hline\n",
      "\t\t\tNT & [3.06 5.45] & [ 9.96 12.36] & [-2.    0.37] \\\\\n",
      "\t\t\tVI & [-3.03 -1.27] & [-0.96  0.9 ] & [-0.07  1.68] \\\\\n",
      "\t\t\tTF & [-4.13 -1.96] & [-3.68 -1.57] & [-4.48 -2.28] \\\\\n",
      "\t\t\t\\hline\n",
      "\t\t\\end{tabular}\n",
      "\t\\end{center}\n",
      "\t\\caption{95\\% Confidence intervals of the gain matrix entries at the equal wealth coordinates}\n",
      "\\end{table}\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "from texttable import Texttable\n",
    "import latextable\n",
    "\n",
    "rows = [['', 'NT', 'VI', 'TF'],\n",
    "        ['NT', str(ci00), str(ci01), str(ci02)],\n",
    "        ['VI', str(ci10), str(ci11), str(ci12)],\n",
    "        ['TF', str(ci20), str(ci21), str(ci22)]]\n",
    "\n",
    "table = Texttable()\n",
    "table.set_cols_align([\"C\"] * 4)\n",
    "table.set_deco(Texttable.HEADER | Texttable.VLINES | Texttable.BORDER)\n",
    "table.add_rows(rows)\n",
    "\n",
    "\n",
    "print('\\nTexttable Table:')\n",
    "print(table.draw())\n",
    "print(latextable.draw_latex(table, caption=\"95\\% Confidence intervals of the gain matrix entries at the equal wealth coordinates\"))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
